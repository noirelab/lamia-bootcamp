{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>243.0000</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>173.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>198.00000</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>205.00000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>111.00000</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.45</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>141.00000</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>206.0000</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>144.00000</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>159.0000</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.98</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>277.00000</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>152.00000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.74</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>165.00000</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>265.0000</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>124.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9456.00</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      radius_mean   texture_mean   perimeter_mean   area_mean  \\\n",
       "0           17.99          10.38           122.80      1001.0   \n",
       "1           20.57          17.77           132.90      1326.0   \n",
       "2           19.69          21.25           130.00      1203.0   \n",
       "3           11.42          20.38            77.58       386.1   \n",
       "4           20.29          14.34           135.10      1297.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564         21.56          22.39           142.00      1479.0   \n",
       "565         20.13          28.25           131.20      1261.0   \n",
       "566         16.60          28.08           108.30       858.1   \n",
       "567         20.60          29.33           140.10      1265.0   \n",
       "568          7.76          24.54            47.92       181.0   \n",
       "\n",
       "      smoothness_mean   compactness_mean   concavity_mean  \\\n",
       "0             0.11840            0.27760          0.30010   \n",
       "1             0.08474            0.07864          0.08690   \n",
       "2             0.10960            0.15990          0.19740   \n",
       "3             0.14250            0.28390          0.24140   \n",
       "4             0.10030            0.13280        198.00000   \n",
       "..                ...                ...              ...   \n",
       "564         111.00000            0.11590          0.24390   \n",
       "565           0.09780            0.10340        144.00000   \n",
       "566           0.08455            0.10230          0.09251   \n",
       "567           0.11780          277.00000          0.35140   \n",
       "568           0.05263            0.04362          0.00000   \n",
       "\n",
       "     concave_points_mean   symmetry_mean   fractal_dimension_mean  ...  \\\n",
       "0                0.14710          0.2419                  0.07871  ...   \n",
       "1                0.07017          0.1812                  0.05667  ...   \n",
       "2                0.12790          0.2069                  0.05999  ...   \n",
       "3                0.10520          0.2597                  0.09744  ...   \n",
       "4                0.10430          0.1809                  0.05883  ...   \n",
       "..                   ...             ...                      ...  ...   \n",
       "564              0.13890          0.1726                  0.05623  ...   \n",
       "565              0.09791          0.1752                  0.05533  ...   \n",
       "566              0.05302        159.0000                  0.05648  ...   \n",
       "567            152.00000          0.2397                  0.07016  ...   \n",
       "568              0.00000          0.1587                  0.05884  ...   \n",
       "\n",
       "      radius_worst   texture_worst   perimeter_worst   area_worst  \\\n",
       "0            25.38           17.33            184.60       2019.0   \n",
       "1            24.99           23.41            158.80       1956.0   \n",
       "2            23.57           25.53            152.50       1709.0   \n",
       "3            14.91           26.50             98.87        567.7   \n",
       "4            22.54           16.67            152.20       1575.0   \n",
       "..             ...             ...               ...          ...   \n",
       "564          25.45           26.40            166.10       2027.0   \n",
       "565          23.69           38.25            155.00       1731.0   \n",
       "566          18.98           34.12            126.70       1124.0   \n",
       "567          25.74           39.42            184.60       1821.0   \n",
       "568        9456.00           30.37             59.16        268.6   \n",
       "\n",
       "      smoothness_worst   compactness_worst   concavity_worst  \\\n",
       "0              0.16220             0.66560            0.7119   \n",
       "1              0.12380             0.18660            0.2416   \n",
       "2              0.14440             0.42450            0.4504   \n",
       "3              0.20980             0.86630            0.6869   \n",
       "4              0.13740           205.00000            0.4000   \n",
       "..                 ...                 ...               ...   \n",
       "564          141.00000             0.21130            0.4107   \n",
       "565            0.11660             0.19220            0.3215   \n",
       "566            0.11390             0.30940            0.3403   \n",
       "567          165.00000             0.86810            0.9387   \n",
       "568            0.08996             0.06444            0.0000   \n",
       "\n",
       "      concave_points_worst   symmetry_worst   fractal_dimension_worst  \n",
       "0                   0.2654           0.4601                   0.11890  \n",
       "1                 186.0000         275.0000                   0.08902  \n",
       "2                 243.0000           0.3613                   0.08758  \n",
       "3                   0.2575           0.6638                 173.00000  \n",
       "4                   0.1625           0.2364                   0.07678  \n",
       "..                     ...              ...                       ...  \n",
       "564                 0.2216         206.0000                   0.07115  \n",
       "565                 0.1628           0.2572                   0.06637  \n",
       "566                 0.1418           0.2218                   0.07820  \n",
       "567               265.0000           0.4087                 124.00000  \n",
       "568                 0.0000           0.2871                   0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv('C:/Users/kaiqu/LAMIA/CARD 12/02 - Classificação Binária - Base Breast Cancer/entradas_breast.csv')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "564  0\n",
       "565  0\n",
       "566  0\n",
       "567  0\n",
       "568  1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classe\n",
    "y = pd.read_csv('C:/Users/kaiqu/LAMIA/CARD 12/02 - Classificação Binária - Base Breast Cancer/saidas_breast.csv')\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_treinamento:\t (426, 30)\n",
      "y_treinamento:\t (426, 1)\n",
      "x_teste:\t (143, 30)\n",
      "y_teste:\t (143, 1)\n"
     ]
    }
   ],
   "source": [
    "# 75% pra treinar, 25% pra testar\n",
    "x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(x, y, test_size = 0.25)\n",
    "\n",
    "print(f'x_treinamento:\\t {x_treinamento.shape}') # 426 registros para treinar, 30 previsores\n",
    "print(f'y_treinamento:\\t {y_treinamento.shape}')\n",
    "print(f'x_teste:\\t {x_teste.shape}') # 143 registro, 30 previsores\n",
    "print(f'y_teste:\\t {y_teste.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (30 + 1) / 2\n",
    "# = 15.5\n",
    "# -> 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural = Sequential([\n",
    "    # shape = quantidade de neurônios na camada, 30 pois há 30 previsores\n",
    "    # dense = rede neural densa. neuronio de uma camda est  conectado a todfos neuronios da proxima camda\n",
    "\n",
    "    # camada de entrada\n",
    "    tf.keras.layers.InputLayer(shape = (30,)),\n",
    "    # camada oculta\n",
    "    tf.keras.layers.Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform'),\n",
    "    # mais uma camada oculta\n",
    "    tf.keras.layers.Dense(units = 16, activation='relu', kernel_initializer=('random_uniform')),\n",
    "    # camada de saida\n",
    "    tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "])\n",
    "# rede neural criada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,357</span> (9.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,357\u001b[0m (9.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">785</span> (3.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m785\u001b[0m (3.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,572</span> (6.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,572\u001b[0m (6.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rede_neural.summary() # 496 = 30 * 16 + 16 (bias) -> neuronio adicional ligando-se a cada uma dos neuronios da camada de entrada\n",
    "# 496 + 17 = 513\n",
    "# 513 parametros totais, indicam os pesos que serão ajustados durante a etapa de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning é padrao 0.001\n",
    "# o gradiente d cada peso é clipado para não ser maior que o valor passado como parêmtro\n",
    "otimizador = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = algoritmo de otimização\n",
    "# loss = cálculo dos erros\n",
    "# metrics = métrica de avaliação da rede neural (precisão)\n",
    "rede_neural.compile(optimizer = otimizador, loss = 'binary_crossentropy', metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - binary_accuracy: 0.5911 - loss: 1.0059   \n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - binary_accuracy: 0.7338 - loss: 0.5177\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8210 - loss: 0.4162\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - binary_accuracy: 0.7341 - loss: 0.5499\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - binary_accuracy: 0.7811 - loss: 0.5678\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8684 - loss: 0.3711\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8487 - loss: 0.4132\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8424 - loss: 0.3838\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8248 - loss: 0.4016\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8128 - loss: 0.5065\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8445 - loss: 0.3802\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8583 - loss: 0.4126\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8245 - loss: 0.6419\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8448 - loss: 0.4136\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.7862 - loss: 0.4901\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8452 - loss: 0.3925\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8548 - loss: 0.3824\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - binary_accuracy: 0.8885 - loss: 0.2951\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.7979 - loss: 0.4659\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8502 - loss: 0.3792 \n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - binary_accuracy: 0.8302 - loss: 0.5606\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8254 - loss: 0.4776\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8736 - loss: 0.3899\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8125 - loss: 0.8656\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8211 - loss: 0.4567\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8189 - loss: 0.4122\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8401 - loss: 0.3860\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8136 - loss: 0.4818\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8255 - loss: 0.4986\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8868 - loss: 0.3536\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8926 - loss: 0.3140\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - binary_accuracy: 0.8544 - loss: 0.3349\n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8761 - loss: 0.3834\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8348 - loss: 0.3830\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8322 - loss: 0.4096 \n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - binary_accuracy: 0.8415 - loss: 0.4774\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8099 - loss: 0.5528\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8245 - loss: 0.4928\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8480 - loss: 0.3970\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8586 - loss: 0.5353\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8811 - loss: 0.5501\n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8725 - loss: 0.4147\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8509 - loss: 0.5469\n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8433 - loss: 0.3742\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - binary_accuracy: 0.8189 - loss: 0.7573\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.7919 - loss: 0.4968\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8770 - loss: 0.3131\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8393 - loss: 0.6100\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8483 - loss: 0.4210\n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8316 - loss: 0.4378\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - binary_accuracy: 0.8610 - loss: 0.4113\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8047 - loss: 0.9908\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - binary_accuracy: 0.8187 - loss: 0.6236\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8703 - loss: 0.3758\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.7957 - loss: 0.8914\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.7724 - loss: 0.8153\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8515 - loss: 0.7531\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.7987 - loss: 0.6469\n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - binary_accuracy: 0.8184 - loss: 0.6951\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8420 - loss: 0.4849\n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8453 - loss: 0.4359\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8331 - loss: 0.5254\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8361 - loss: 0.4515\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8208 - loss: 0.6220\n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8583 - loss: 0.4270\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8714 - loss: 0.4778\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - binary_accuracy: 0.7460 - loss: 1.2543\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8020 - loss: 0.5678\n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - binary_accuracy: 0.8563 - loss: 0.4692\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8535 - loss: 0.6535\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.7944 - loss: 0.6600\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - binary_accuracy: 0.7977 - loss: 0.4690\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8563 - loss: 0.4861\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - binary_accuracy: 0.8036 - loss: 0.5577\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8554 - loss: 0.4346\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8448 - loss: 0.4033\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8063 - loss: 0.7682\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8661 - loss: 0.3898\n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8787 - loss: 0.4329\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8260 - loss: 0.7633\n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - binary_accuracy: 0.8245 - loss: 0.5567\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8206 - loss: 0.4979\n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8662 - loss: 0.5226\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - binary_accuracy: 0.8854 - loss: 0.3810\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8610 - loss: 0.5222\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8304 - loss: 0.5574 \n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - binary_accuracy: 0.8483 - loss: 0.4833\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8457 - loss: 0.6355\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8346 - loss: 0.7356\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - binary_accuracy: 0.8782 - loss: 0.4310\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8601 - loss: 0.4462\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8249 - loss: 0.5352\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8425 - loss: 0.4549\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8723 - loss: 0.4204\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - binary_accuracy: 0.8516 - loss: 0.5889\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8490 - loss: 0.5031\n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - binary_accuracy: 0.8791 - loss: 0.4746\n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8447 - loss: 0.5908\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.8580 - loss: 0.4407\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.8654 - loss: 0.4272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1611c7506e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rede_neural.fit(x_treinamento, y_treinamento, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-2.01208014e-02, -2.95982987e-01, -1.85327187e-01,\n",
       "          1.33825436e-01, -3.54483068e-01,  1.58773690e-01,\n",
       "          3.89179867e-03,  1.07393609e-02, -4.09144536e-02,\n",
       "         -2.74246149e-02, -8.70137885e-02, -1.17549850e-02,\n",
       "         -1.74473692e-02, -4.95664515e-02,  8.52029622e-02,\n",
       "         -7.43374750e-02],\n",
       "        [-4.26714160e-02, -2.79633313e-01, -1.99746251e-01,\n",
       "          2.72859246e-01, -4.46832150e-01,  3.81905548e-02,\n",
       "         -1.36956815e-02, -9.80838463e-02, -4.50005680e-02,\n",
       "         -1.52827024e-01, -9.97298509e-02,  1.18030399e-01,\n",
       "          1.93927437e-01,  7.00693727e-02,  3.71918716e-02,\n",
       "         -1.76762685e-01],\n",
       "        [ 5.44494763e-03, -7.95559809e-02,  7.91169405e-02,\n",
       "          1.73499152e-01, -3.32455873e-01,  1.54669836e-01,\n",
       "          8.42849538e-02,  6.54872879e-02,  1.49554526e-03,\n",
       "         -1.03324212e-01, -9.09528136e-02,  6.63971528e-02,\n",
       "         -8.64199642e-03, -7.97806755e-02, -6.87429085e-02,\n",
       "          9.09301788e-02],\n",
       "        [ 2.69659166e-03,  6.60813600e-02,  4.72637191e-02,\n",
       "         -4.83350269e-02, -5.11699840e-02,  6.66917488e-02,\n",
       "          2.93506794e-02, -1.08232284e-02,  2.97015477e-02,\n",
       "         -4.11370769e-03, -4.71711205e-03, -7.62361661e-02,\n",
       "          4.68800552e-02,  3.01736742e-02, -7.11904541e-02,\n",
       "          4.19479273e-02],\n",
       "        [-6.26717433e-02, -4.67308313e-02, -9.66163352e-02,\n",
       "          3.83019559e-02, -9.95661244e-02, -1.14806511e-01,\n",
       "         -2.53046453e-01, -7.62015209e-02,  3.93257849e-02,\n",
       "          5.94323389e-02,  1.64162405e-02, -5.85891714e-04,\n",
       "          9.30225998e-02,  1.39600113e-01, -8.80236775e-02,\n",
       "         -3.88168618e-02],\n",
       "        [-1.70494258e-01, -2.24234760e-01, -5.77089489e-02,\n",
       "          3.31238151e-01, -1.39318258e-01,  7.57496953e-02,\n",
       "          5.82482899e-03,  3.20122540e-02, -1.33188874e-01,\n",
       "         -1.24668041e-02,  3.17010283e-02, -4.29606438e-02,\n",
       "          1.29720181e-01,  9.11855176e-02,  1.61717553e-02,\n",
       "         -8.79075155e-02],\n",
       "        [-5.98147251e-02, -2.08537236e-01, -5.95029555e-02,\n",
       "          3.74268234e-01, -2.51726031e-01, -1.05914883e-02,\n",
       "         -7.27581158e-02,  1.20376395e-02,  1.38117941e-02,\n",
       "         -1.99887753e-01, -8.32164884e-02, -7.32956454e-02,\n",
       "          1.49957687e-01,  1.30307907e-02, -9.37321037e-03,\n",
       "          6.17421158e-02],\n",
       "        [-9.30168480e-02, -3.48852992e-01, -1.25222027e-01,\n",
       "         -1.30226552e-01,  9.60422456e-02,  1.19453244e-01,\n",
       "          7.38109574e-02,  3.47488113e-02, -5.56098996e-03,\n",
       "         -5.85104860e-02,  8.47434327e-02,  3.65288444e-02,\n",
       "         -6.05573207e-02, -9.56862271e-02,  1.32561356e-01,\n",
       "          8.27713162e-02],\n",
       "        [-9.69184376e-03,  1.19662015e-02,  1.86751753e-01,\n",
       "          6.74656257e-02,  4.13339622e-02,  8.23491514e-02,\n",
       "          1.38526574e-01,  4.61170375e-02, -7.27275386e-02,\n",
       "         -1.17153890e-01,  5.82142472e-02,  2.06975549e-01,\n",
       "         -3.82438451e-02,  2.01139264e-02,  2.27694260e-03,\n",
       "          1.25245512e-01],\n",
       "        [-2.05773395e-03,  1.55775473e-01,  5.58806598e-01,\n",
       "          1.22289322e-02,  2.16023073e-01,  4.25986320e-01,\n",
       "          3.90917152e-01,  8.99236500e-02,  7.38604814e-02,\n",
       "         -1.32105112e-01, -1.28797339e-02, -1.54555663e-01,\n",
       "         -6.03867471e-01, -3.18331599e-01, -2.34869216e-02,\n",
       "          1.84187800e-01],\n",
       "        [-2.25629807e-02, -2.64515951e-02,  6.36691749e-02,\n",
       "          1.27399832e-01, -9.05958004e-03,  1.84418336e-02,\n",
       "         -4.85347807e-02, -1.34590259e-02, -4.98231910e-02,\n",
       "          2.54951604e-02, -7.87617713e-02,  1.28782809e-01,\n",
       "          9.12225768e-02,  4.28963564e-02, -8.20390973e-03,\n",
       "         -2.76288036e-02],\n",
       "        [-3.10126971e-02, -3.38384986e-01, -2.61217053e-03,\n",
       "          1.20696805e-01,  2.64546186e-01,  1.61644042e-01,\n",
       "          4.56864499e-02,  9.82186198e-03,  1.35102123e-02,\n",
       "         -6.34445390e-03, -3.10146734e-02, -6.34602830e-02,\n",
       "         -1.10066660e-01, -3.54813039e-02, -1.60956070e-01,\n",
       "          1.78992718e-01],\n",
       "        [ 1.85685828e-02,  1.86590001e-01,  5.82303256e-02,\n",
       "         -9.20558274e-02,  1.06084086e-01, -6.42421935e-03,\n",
       "         -2.90575251e-03, -4.39243689e-02, -1.06541403e-02,\n",
       "          1.03691459e-01,  7.57564977e-02, -1.69021562e-02,\n",
       "          1.60786286e-01,  1.59621969e-01, -2.50900928e-02,\n",
       "          2.53285393e-02],\n",
       "        [-4.49344307e-01, -1.11913645e+00, -1.03213179e+00,\n",
       "          7.19238669e-02, -9.63554859e-01,  1.77958503e-01,\n",
       "         -2.41711840e-01, -2.27308914e-01, -1.76335469e-01,\n",
       "          1.82899624e-01, -3.74990655e-03, -3.70763359e-03,\n",
       "          3.20268035e-01,  4.07767445e-01,  8.75914991e-02,\n",
       "         -5.47873735e-01],\n",
       "        [-2.86383983e-02, -1.68882132e-01, -1.51977152e-01,\n",
       "          1.96747616e-01, -5.53765476e-01,  7.35556381e-03,\n",
       "         -1.80423539e-02, -3.22420113e-02,  7.49806874e-03,\n",
       "         -1.99853688e-01, -1.56651344e-02,  1.20059131e-02,\n",
       "          1.69497594e-01, -4.55141393e-03, -2.99661905e-02,\n",
       "         -1.38151959e-01],\n",
       "        [-5.51048294e-02, -3.41848433e-01, -3.49538565e-01,\n",
       "         -9.87166390e-02, -8.43589529e-02, -3.87552172e-01,\n",
       "         -2.65752345e-01, -5.05553447e-02, -7.55340187e-03,\n",
       "          3.20824623e-01,  1.61723673e-01,  1.04803443e-01,\n",
       "          2.34541088e-01,  1.88609287e-01,  2.45054081e-01,\n",
       "         -1.84066698e-01],\n",
       "        [-8.21804851e-02, -1.51715815e-01, -8.25921297e-02,\n",
       "          4.52539138e-02,  2.53482014e-01, -1.97267130e-01,\n",
       "         -3.40714678e-02, -1.19451527e-02, -3.82178724e-02,\n",
       "          2.32220247e-01,  1.13202214e-01,  1.69923343e-02,\n",
       "         -8.15880299e-02,  7.15966001e-02,  1.81710660e-01,\n",
       "         -9.09271277e-03],\n",
       "        [-3.04893881e-01, -9.96785998e-01, -8.83290946e-01,\n",
       "          2.39929989e-01, -8.44576061e-01, -7.04683781e-01,\n",
       "         -6.24855757e-01, -1.55104652e-01, -1.22183077e-01,\n",
       "          3.37848932e-01,  2.97114313e-01,  4.74987000e-01,\n",
       "          9.10743356e-01,  6.33625686e-01,  5.85217953e-01,\n",
       "         -5.61654508e-01],\n",
       "        [-2.37537920e-02, -2.12678120e-01, -1.20873481e-01,\n",
       "          1.43166572e-01, -3.71634036e-01,  6.96328729e-02,\n",
       "          3.10403593e-02, -1.24273179e-02,  3.38084511e-02,\n",
       "         -1.49513736e-01, -1.20284654e-01, -1.36259040e-02,\n",
       "          3.19606587e-02, -2.59815659e-02, -7.87692443e-02,\n",
       "         -2.82977298e-02],\n",
       "        [-1.11784801e-01, -1.57020107e-01, -7.07265079e-01,\n",
       "          4.91467983e-01, -5.43397963e-01, -3.73559386e-01,\n",
       "         -4.12592322e-01, -6.04083063e-03, -1.20480128e-01,\n",
       "         -5.70494235e-02, -1.09522901e-01,  2.25950465e-01,\n",
       "          6.07697070e-01,  4.02496964e-01,  2.76081618e-02,\n",
       "         -1.12723865e-01],\n",
       "        [-6.83122501e-02, -3.97991955e-01, -3.38705361e-01,\n",
       "          1.21049389e-01, -4.41164136e-01,  1.56310782e-01,\n",
       "         -1.41222239e-01, -5.14053144e-02, -1.76769476e-02,\n",
       "          6.82076961e-02, -2.14676489e-03, -5.30095305e-04,\n",
       "          7.03806281e-02,  1.11011537e-02,  1.37719750e-01,\n",
       "         -1.47089839e-01],\n",
       "        [-1.37901321e-01, -3.56479675e-01, -3.46089989e-01,\n",
       "          3.54533285e-01, -5.81404567e-01, -2.14515552e-02,\n",
       "         -1.79956391e-01, -3.51096466e-02, -3.96508165e-02,\n",
       "         -4.65741195e-02,  2.39029992e-02,  2.43016466e-01,\n",
       "          3.41872573e-01,  2.14676559e-01,  4.50545549e-02,\n",
       "         -1.89411342e-01],\n",
       "        [-3.45059112e-02, -1.58567920e-01, -5.29856831e-02,\n",
       "          2.71854132e-01, -4.44422632e-01,  1.11203954e-01,\n",
       "         -2.66205668e-02,  1.41133014e-02,  2.48521343e-02,\n",
       "         -1.09647058e-01, -2.81165745e-02,  1.23527132e-01,\n",
       "          8.87622386e-02,  7.24932626e-02, -2.13209763e-02,\n",
       "         -1.21607434e-03],\n",
       "        [-7.84705132e-02,  5.93785234e-02, -1.63523350e-02,\n",
       "         -7.81074539e-02, -1.09129727e-01, -1.50868297e-02,\n",
       "         -2.85108592e-02, -4.82973829e-02, -5.82869053e-02,\n",
       "          1.09409377e-01,  2.12652870e-02, -5.74655607e-02,\n",
       "          2.27336690e-01,  2.19614387e-01, -6.87305257e-03,\n",
       "         -1.01677991e-01],\n",
       "        [-2.85912510e-02,  1.17344908e-01,  2.18847096e-02,\n",
       "          1.55077323e-01, -4.51873571e-01, -2.69850455e-02,\n",
       "         -1.01142034e-01, -7.07478076e-02,  2.17694435e-02,\n",
       "         -1.56117216e-01, -1.09146439e-01,  1.72484785e-01,\n",
       "          2.63539851e-01,  6.49837255e-02, -3.50408815e-02,\n",
       "          2.70503797e-02],\n",
       "        [-5.87993674e-02, -3.94227616e-02,  2.10963950e-01,\n",
       "          7.72132799e-02, -4.53451835e-02,  1.22705050e-01,\n",
       "          3.05734836e-02,  4.29688171e-02, -6.80207685e-02,\n",
       "          1.27732441e-01,  1.03330158e-01,  2.23025814e-01,\n",
       "          1.67750135e-01,  1.72782764e-01,  5.46101993e-03,\n",
       "          5.28027341e-02],\n",
       "        [-5.54177500e-02, -1.08056925e-01,  1.08980834e-01,\n",
       "          1.00358576e-01,  2.73242444e-01,  1.22728556e-01,\n",
       "          1.07890420e-01, -1.76364388e-02, -1.83352493e-02,\n",
       "         -1.63150497e-03, -1.28857657e-01,  2.53744543e-01,\n",
       "          3.70639786e-02, -3.63678485e-02, -1.93984192e-02,\n",
       "          6.13124929e-02],\n",
       "        [-6.17685840e-02, -2.94878721e-01, -2.25538850e-01,\n",
       "          2.44292483e-01, -5.17831743e-02,  1.53953597e-01,\n",
       "          3.82613055e-02, -2.95587844e-04, -6.82891980e-02,\n",
       "          2.65272427e-02, -6.93762377e-02,  2.39914328e-01,\n",
       "          1.60498425e-01,  1.90381870e-01, -5.10502085e-02,\n",
       "         -1.91798627e-01],\n",
       "        [-6.55684387e-03,  6.69874698e-02,  1.74197838e-01,\n",
       "         -4.50065956e-02, -1.36597022e-01,  2.02550925e-02,\n",
       "         -1.24004506e-01, -3.04742157e-02, -5.37328869e-02,\n",
       "          1.24754779e-01, -5.71675971e-02,  2.62694042e-02,\n",
       "          1.22402944e-01,  7.45389238e-02, -3.00634187e-02,\n",
       "          1.38781503e-01],\n",
       "        [-2.62696177e-01, -3.38562548e-01, -5.44803619e-01,\n",
       "         -7.96566531e-02, -5.85310042e-01, -1.56613275e-01,\n",
       "         -2.08162323e-01, -1.44256666e-01, -1.77009776e-01,\n",
       "          1.57193795e-01,  7.71105513e-02,  3.28269929e-01,\n",
       "          3.82600546e-01,  2.85558760e-01,  6.23744503e-02,\n",
       "         -3.75085443e-01]], dtype=float32),\n",
       " array([ 0.14354229,  0.14849493,  0.29234388,  0.15321462, -0.12225021,\n",
       "         0.5279073 ,  0.44822875,  0.11082298,  0.1047894 , -0.5105428 ,\n",
       "        -0.31881723, -0.25487435, -0.4449695 , -0.44025603, -0.33765033,\n",
       "         0.2326772 ], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos0 = rede_neural.layers[0].get_weights()\n",
    "pesos0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pesos0) # 2 arrays\n",
    "# 1 array de cada neuronio da camada de entrada\n",
    "# 1 array de cada neuronio da camada oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pesos0[1]) # 16 neuronios na camada oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30 valores, pesos de cada neuronio da camada de entrada com cada um dos neuronios da camada oculta\n",
    "len(pesos0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-9.59523674e-03, -5.91012910e-02,  1.20880874e-02,\n",
       "         -1.07124351e-01, -4.28619273e-02,  2.85302699e-02,\n",
       "         -7.13434443e-03, -5.71541786e-02,  3.05078626e-02,\n",
       "          1.71147212e-01, -7.06161037e-02, -6.75285701e-03,\n",
       "          4.41344362e-03, -1.15901744e-02, -3.52462046e-02,\n",
       "         -6.42150491e-02],\n",
       "        [-4.09961715e-02,  4.96783294e-02,  3.74717731e-03,\n",
       "          1.23223616e-02,  1.46103259e-02, -4.76674549e-02,\n",
       "          4.02067136e-03, -1.21896807e-02,  2.31119022e-01,\n",
       "         -7.27374107e-02, -2.05888785e-02,  2.23033000e-02,\n",
       "          2.04350688e-02, -4.18524966e-02,  2.56205313e-02,\n",
       "         -6.59037754e-02],\n",
       "        [-2.74444576e-02, -6.31281361e-02, -3.70098278e-02,\n",
       "          7.07225502e-03, -1.10028861e-02, -4.69744485e-03,\n",
       "         -5.89523278e-02,  1.04503267e-01,  1.11415818e-01,\n",
       "         -2.57743653e-02,  1.58984810e-02,  1.95040144e-02,\n",
       "         -3.67419049e-02, -1.11735247e-01, -9.99674108e-03,\n",
       "         -2.62821862e-03],\n",
       "        [-3.74875888e-02,  4.25686128e-02,  3.28934938e-02,\n",
       "         -1.56178877e-01, -4.68271747e-02,  9.40447673e-04,\n",
       "         -3.40471230e-02, -5.13433069e-02, -7.59933963e-02,\n",
       "          1.04489319e-01, -6.61240378e-03,  1.52899753e-02,\n",
       "         -2.80031767e-02,  1.34066895e-01,  1.44394757e-02,\n",
       "         -1.62591159e-01],\n",
       "        [ 3.38600799e-02,  6.15816377e-02, -4.51036692e-02,\n",
       "          1.87073313e-02,  1.20368004e-02, -4.60220166e-02,\n",
       "         -2.94584967e-02, -2.82193869e-02,  1.78690493e-01,\n",
       "          1.16424412e-02,  3.03549264e-02,  2.45814212e-02,\n",
       "         -3.72923799e-02, -1.07924953e-01,  2.89421491e-02,\n",
       "          8.18733349e-02],\n",
       "        [-5.14109507e-02,  7.16640800e-02, -1.57774743e-02,\n",
       "          1.77238494e-01, -2.55374499e-02, -9.97303985e-03,\n",
       "         -1.28132645e-02,  5.00815883e-02,  1.09131210e-01,\n",
       "         -2.46953573e-02, -1.84111059e-01, -5.99212050e-02,\n",
       "         -5.07371388e-02, -7.80870691e-02, -2.79690046e-02,\n",
       "         -1.37395188e-01],\n",
       "        [-3.62782218e-02, -1.63653009e-02, -5.45248501e-02,\n",
       "          8.47429633e-02,  3.06119975e-02, -4.90119904e-02,\n",
       "         -5.80272712e-02, -2.26743057e-01,  2.14511193e-02,\n",
       "          7.19898418e-02, -3.22828174e-01,  1.57715473e-02,\n",
       "          2.74702832e-02,  2.75075156e-02, -3.92807350e-02,\n",
       "         -7.04708397e-02],\n",
       "        [ 1.25107933e-02,  4.64139925e-03, -4.55610901e-02,\n",
       "         -6.76775128e-02,  1.41604887e-02, -2.14811694e-03,\n",
       "         -2.71156989e-02, -1.75179206e-02,  5.59731200e-02,\n",
       "          1.53521776e-01,  3.85022648e-02, -5.51957116e-02,\n",
       "          5.45837032e-03,  5.83309308e-02,  1.41567271e-03,\n",
       "         -9.20446441e-02],\n",
       "        [-1.87094212e-02, -3.40052806e-02, -1.61981322e-02,\n",
       "         -5.31278811e-02, -3.11088618e-02, -3.79110165e-02,\n",
       "          2.86508556e-02,  1.63824130e-02,  7.64234969e-03,\n",
       "          6.45443648e-02, -2.89102513e-02, -2.90681329e-02,\n",
       "         -3.43231671e-02,  4.91934642e-02,  5.79760550e-03,\n",
       "         -3.88660170e-02],\n",
       "        [-3.06180734e-02,  3.37154465e-03, -1.05744623e-01,\n",
       "         -3.57418670e-03, -3.45465057e-02, -4.74815406e-02,\n",
       "         -6.12843111e-02, -8.37120786e-02, -6.60231262e-02,\n",
       "          4.98749837e-02, -1.53069472e-04, -3.59390117e-02,\n",
       "         -3.92355695e-02,  1.26230596e-02, -3.56434546e-02,\n",
       "          5.68408035e-02],\n",
       "        [-2.80349161e-02, -5.78924306e-02, -5.48432805e-02,\n",
       "          9.19403583e-02,  1.14855720e-02, -1.38780093e-02,\n",
       "         -2.17412710e-02, -1.99391723e-01,  3.59691158e-02,\n",
       "          2.09735078e-03, -2.13000789e-01,  3.50903044e-03,\n",
       "         -4.60251793e-02, -2.92284973e-02,  1.19111650e-02,\n",
       "          1.74820274e-02],\n",
       "        [-2.50303727e-02, -1.66506395e-02,  1.17889773e-02,\n",
       "         -1.06235564e-01, -2.45258044e-02, -4.70827594e-02,\n",
       "         -1.69165265e-02, -2.15453848e-01, -7.76416734e-02,\n",
       "          1.03846632e-01, -1.03314504e-01,  2.71136947e-02,\n",
       "          2.62615792e-02,  3.19993123e-02,  1.27849467e-02,\n",
       "         -2.23403722e-02],\n",
       "        [-4.85792011e-02, -1.82895306e-02,  2.05227379e-02,\n",
       "         -9.26056597e-03,  2.24884832e-03, -1.03910834e-01,\n",
       "         -3.89920883e-02,  6.27397513e-03, -6.60585910e-02,\n",
       "          1.11227050e-01,  5.14966063e-02, -3.28934006e-02,\n",
       "         -5.65401977e-03, -5.14349155e-03, -4.67175506e-02,\n",
       "         -5.75558608e-03],\n",
       "        [-1.88809521e-02,  3.76730263e-02, -7.18979239e-02,\n",
       "         -1.54700810e-02, -5.85221387e-02, -8.05027410e-03,\n",
       "         -8.38054251e-03,  1.02495484e-01, -7.58968890e-02,\n",
       "          1.50957247e-02,  5.12657166e-02, -4.60846908e-02,\n",
       "         -3.34372781e-02,  1.82700474e-02, -4.16808277e-02,\n",
       "          5.22171594e-02],\n",
       "        [-9.17747896e-03,  3.44568156e-02,  1.16641996e-02,\n",
       "         -4.22370806e-03, -2.47514788e-02, -5.01154922e-02,\n",
       "         -3.12339906e-02,  1.30978167e-01, -1.12068683e-01,\n",
       "         -1.26612708e-02, -5.28733805e-03, -4.63760570e-02,\n",
       "         -8.06712266e-03, -3.40466276e-02, -2.40740739e-02,\n",
       "          1.22120075e-01],\n",
       "        [ 1.94593333e-02,  4.05377261e-02, -8.99693742e-02,\n",
       "         -5.38334511e-02, -1.84403230e-02, -5.11876605e-02,\n",
       "         -5.09098545e-03, -1.77337881e-02,  2.48206295e-02,\n",
       "          1.45321891e-01,  5.88737093e-02, -2.38579102e-02,\n",
       "          2.20711119e-02,  4.54746634e-02,  4.68454557e-03,\n",
       "         -1.00735880e-01]], dtype=float32),\n",
       " array([-0.01763651, -0.02333377, -0.03392912,  0.5639002 , -0.00516109,\n",
       "        -0.03767395, -0.00453043,  0.26714864,  0.29893497, -0.41322216,\n",
       "         0.03284322, -0.0108621 , -0.01875753, -0.40706632, -0.01060678,\n",
       "        -0.42743766], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos1 = rede_neural.layers[1].get_weights()\n",
    "pesos1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.2564357 ],\n",
       "        [ 0.06567337],\n",
       "        [ 0.16781795],\n",
       "        [ 0.19216558],\n",
       "        [-0.47508198],\n",
       "        [-0.14035487],\n",
       "        [-0.00561823],\n",
       "        [ 0.12687635],\n",
       "        [ 0.17070256],\n",
       "        [-0.17902124],\n",
       "        [ 0.03072713],\n",
       "        [-0.4718436 ],\n",
       "        [-0.13237138],\n",
       "        [-0.168199  ],\n",
       "        [-0.07574373],\n",
       "        [-0.65224427]], dtype=float32),\n",
       " array([0.4368106], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos2 = rede_neural.layers[2].get_weights()\n",
    "pesos2 # 16 neuronios na camada oculta ligados a camada saida + o do bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step\n"
     ]
    }
   ],
   "source": [
    "previsoes = rede_neural.predict(x_teste)\n",
    "previsoes = (previsoes) > 0.5 # indica se a previsão é verdadeira ou falsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "208  1\n",
       "117  0\n",
       "214  0\n",
       "442  1\n",
       "138  0\n",
       "..  ..\n",
       "561  1\n",
       "508  1\n",
       "500  1\n",
       "244  0\n",
       "444  0\n",
       "\n",
       "[143 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste # comparando o true com o 1 para saber se é cancer ou não"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8251748251748252"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53,  4],\n",
       "       [21, 65]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_teste, previsoes)\n",
    "# 53 + 65 = 118 acertos\n",
    "# 21 +  4 = 25 erros\n",
    "# 118 / 143 = 0.8251 (accuracy_score)\n",
    "# erro = 25 / 143 = 0.1748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7201 - loss: 1.6732  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6668457984924316, 0.6993007063865662]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rede_neural.evaluate(x_teste, y_teste)\n",
    "# 0.53 erro\n",
    "# 0.8251 acerto\n",
    "\n",
    "# maior numero de camadas é só pra problemas mais complexos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
