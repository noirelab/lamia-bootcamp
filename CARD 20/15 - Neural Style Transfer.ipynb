{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "from torchvision import transforms as T\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import vgg19\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.Lambda(lambda x: x.mul_(255))\n",
    "])\n",
    "\n",
    "postprocess = T.Compose([\n",
    "    T.Lambda(lambda x: x.mul_(1/255)),\n",
    "    T.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GranMatrix(nn.Module):\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        feat = x.view(b, c, h*w)\n",
    "        G = feat@feat.transpose(1, 2)\n",
    "        G.div_(h*w)\n",
    "        return G\n",
    "\n",
    "class GramMSELoss(nn.Module):\n",
    "    def forward(self, input, target):\n",
    "        out = F.mse_loss(GranMatrix()(input), target)\n",
    "        return out\n",
    "\n",
    "class vgg19_modified(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        features = list(vgg19(pretrained = True).features)\n",
    "        self.features = nn.ModuleList(features).eval()\n",
    "\n",
    "    def forward(self, x, layers = []):\n",
    "        order = np.argsort(layers)\n",
    "        _results, results = [], []\n",
    "\n",
    "        for ix, model in enumerate(self.features):\n",
    "            x = model(x)\n",
    "            if ix in layers:\n",
    "                _results.append(x)\n",
    "        for o in order:\n",
    "            results.append(_results[o])\n",
    "\n",
    "        return results if layers is not [] else x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaiqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kaiqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vgg = vgg19_modified().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %wget https://easydrawingguides.com/wp-content/uploads/2016/10/how-to-draw-an-elephant-featured-image-1200-1024x822.png\n",
    "# %wget https://www.neh.gov/sites/default/files/2022-09/Fall_2022_web-images_Picasso_32.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [Image.open(path).resize((512, 512)).convert('RGB') for path in ['how-to-draw-an-elephant-featured-image-1200-1024x822.png', 'Picasso.jpg']]\n",
    "style_image, content_image = [preprocess(img).to(device)[None] for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_img = content_image.data.clone()\n",
    "opt_img.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layers = [0, 5, 10, 19, 28]\n",
    "content_layers = [21]\n",
    "loss_layers = style_layers + content_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fns = [GramMSELoss()] * len(style_layers) + [nn.MSELoss()] * len(content_layers)\n",
    "loss_fns = [loss_fn.to(device) for loss_fn in loss_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_weights = [1000/n**2 for n in [64, 128, 256, 512, 512]]\n",
    "content_weight = [1] # tem que ser em lista mesmo\n",
    "weights = style_weights + content_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_targets = [GranMatrix()(A).detach() for A in vgg(style_image, style_layers)]\n",
    "content_targets = [A.detach() for A in vgg(content_image, content_layers)]\n",
    "targets = style_targets + content_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 500\n",
    "optimizer = optim.LBFGS([opt_img])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "iters = 0\n",
    "loss_record = []\n",
    "\n",
    "while iters < max_iters:\n",
    "    def closure():\n",
    "        global iters\n",
    "        iters += 1\n",
    "        optimizer.zero_grad()\n",
    "        out = vgg(opt_img, loss_layers)\n",
    "        layer_losses = [weights[a] * loss_fns[a](A, targets[a]) for a, A in enumerate(out)]\n",
    "        loss = sum(layer_losses)\n",
    "        loss.backward()\n",
    "        loss_record.append(loss.item())\n",
    "\n",
    "        return loss\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Após o loop, você pode gerar o gráfico da perda:\n",
    "plt.plot(loss_record)  # Plota os valores de perda registrados\n",
    "plt.xlabel('Iterações')  # Rótulo do eixo X\n",
    "plt.ylabel('Perda')  # Rótulo do eixo Y\n",
    "plt.title('Progresso da Perda Durante as Iterações')  # Título do gráfico\n",
    "plt.show()  # Exibe o gráfico"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
